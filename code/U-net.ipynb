{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 说明\r\n",
    "https://www.kaggle.com/balraj98/stanford-background-dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 相关依赖"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\r\n",
    "import torchvision\r\n",
    "from torchvision import datasets, transforms\r\n",
    "from PIL import Image\r\n",
    "import matplotlib.image as IMG\r\n",
    "import shutil\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据集划分\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "#   分割训练集和测试集\r\n",
    "files = os.listdir('../cropped_dataset/images/')\r\n",
    "img_and_lables = []\r\n",
    "for i in files:\r\n",
    "    img_and_lables.append(('../cropped_dataset/images/'+i,'../cropped_dataset/labels/'+i.split('.')[0]+'.txt'))\r\n",
    "\r\n",
    "train_set, test_set = random_split(\r\n",
    "    dataset=img_and_lables,\r\n",
    "    lengths=[650,65],\r\n",
    "    generator=torch.Generator().manual_seed(0)\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset & Dataloader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "#   dataset\r\n",
    "class DataSet(Dataset):\r\n",
    "    def __init__(self,dataSet):\r\n",
    "        self.dataset = dataSet\r\n",
    "       \r\n",
    "    def __getitem__(self, index):\r\n",
    "        pic = IMG.imread(self.dataset[index][0])\r\n",
    "        with open(self.dataset[index][1],\"r\") as f:    #设置文件对象\r\n",
    "            label_str = f.read()    #可以是随便对文件的操作\r\n",
    "        \r\n",
    "        pic = torch.from_numpy(pic).transpose(0,2).transpose(1,2).float()/255\r\n",
    "        \r\n",
    "        return pic,label_str\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.dataset)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型搭建\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "class UNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super().__init__()\r\n",
    "        self.overlapTile = nn.ReflectionPad2d(30)\r\n",
    "\r\n",
    "        self.conv1_1 = nn.Conv2d(3,64,3,1)\r\n",
    "        self.conv1_2 = nn.Conv2d(64,64,3,1)\r\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\r\n",
    "\r\n",
    "        self.conv2_1 = nn.Conv2d(64,128,3,1)\r\n",
    "        self.conv2_2 = nn.Conv2d(128,128,3,1)\r\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\r\n",
    "\r\n",
    "        self.conv3_1 = nn.Conv2d(128,256,3,1)\r\n",
    "        self.conv3_2 = nn.Conv2d(256,256,3,1)\r\n",
    "        self.pool3 = nn.MaxPool2d(2,2)\r\n",
    "\r\n",
    "        self.conv4_1 = nn.Conv2d(256,512,3,1)\r\n",
    "        self.conv4_2 = nn.Conv2d(512,512,3,1)\r\n",
    "        self.pool4 = nn.MaxPool2d(2,2)\r\n",
    "\r\n",
    "        self.conv5_1 = nn.Conv2d(512,1024,3,1)\r\n",
    "        self.conv5_2 = nn.Conv2d(1024,512,3,1)\r\n",
    "\r\n",
    "        self.upconv1 = nn.ConvTranspose2d(512,512,2,2)\r\n",
    "\r\n",
    "        self.conv6_1 = nn.Conv2d(1024,512,3,1)\r\n",
    "        self.conv6_2 = nn.Conv2d(512,256,3,1)\r\n",
    "\r\n",
    "        self.upconv2 = nn.ConvTranspose2d(256,256,2,2)\r\n",
    "\r\n",
    "        self.conv7_1 = nn.Conv2d(512,256,3,1)\r\n",
    "        self.conv7_2 = nn.Conv2d(256,128,3,1)\r\n",
    "\r\n",
    "        self.upconv3 = nn.ConvTranspose2d(128,128,2,2)\r\n",
    "\r\n",
    "        self.conv8_1 = nn.Conv2d(256,128,3,1)\r\n",
    "        self.conv8_2 = nn.Conv2d(128,64,3,1)\r\n",
    "\r\n",
    "        self.upconv4 = nn.ConvTranspose2d(64,64,2,2)\r\n",
    "\r\n",
    "        self.conv9_1 = nn.Conv2d(128,64,3,1)\r\n",
    "        self.conv9_2 = nn.Conv2d(64,64,3,1)\r\n",
    "        self.conv9_3 = nn.Conv2d(64,9,1,1)\r\n",
    "\r\n",
    "    def forward(self,x):\r\n",
    "        x = self.overlapTile(x) #略\r\n",
    "\r\n",
    "        x = F.relu(self.conv1_1(x))\r\n",
    "        x = F.relu(self.conv1_2(x))\r\n",
    "        Intermediate1 = x[:,:,88:480,88:480] #  cropping to copy\r\n",
    "        x = self.pool1(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv2_1(x))\r\n",
    "        x = F.relu(self.conv2_2(x))\r\n",
    "        Intermediate2 = x[:,:,40:240,40:240]#  cropping to copy\r\n",
    "        x = self.pool2(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv3_1(x))\r\n",
    "        x = F.relu(self.conv3_2(x))\r\n",
    "        Intermediate3 = x[:,:,16:120,16:120]#  cropping to copy\r\n",
    "        x = self.pool3(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv4_1(x))\r\n",
    "        x = F.relu(self.conv4_2(x))\r\n",
    "        Intermediate4 = x[:,:,4:60,4:60]#  cropping to copy\r\n",
    "        x = self.pool4(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv5_1(x))\r\n",
    "        x = F.relu(self.conv5_2(x))\r\n",
    "\r\n",
    "        x = self.upconv1(x)\r\n",
    "        \r\n",
    "        x = F.relu(self.conv6_1(torch.cat((Intermediate4,x),1)))\r\n",
    "        x = F.relu(self.conv6_2(x))\r\n",
    "\r\n",
    "        x = self.upconv2(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv7_1(torch.cat((Intermediate3,x),1)))\r\n",
    "        x = F.relu(self.conv7_2(x))\r\n",
    "\r\n",
    "        x = self.upconv3(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv8_1(torch.cat((Intermediate2,x),1)))\r\n",
    "        x = F.relu(self.conv8_2(x))\r\n",
    "\r\n",
    "        x = self.upconv4(x)\r\n",
    "\r\n",
    "        x = F.relu(self.conv9_1(torch.cat((Intermediate1,x),1)))\r\n",
    "        x = F.relu(self.conv9_2(x))\r\n",
    "        x = self.conv9_3(x)\r\n",
    "\r\n",
    "        return x\r\n",
    "\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 训练与评估"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#   参数设置\r\n",
    "EPOCH_NUM = 5\r\n",
    "BATCH_SIZE = 1\r\n",
    "NUM_WORKERS = 0\r\n",
    "LEARNING_RATE = 0.001\r\n",
    "\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "\r\n",
    "#   initialization for dataset,DataLoader and optimazer\r\n",
    "net = UNet().to(device)\r\n",
    "\r\n",
    "trainingSet = DataSet(train_set)\r\n",
    "testSet = DataSet(test_set)\r\n",
    "\r\n",
    "trainingSet_Loader = DataLoader(trainingSet,\r\n",
    "                                batch_size = BATCH_SIZE,\r\n",
    "                                num_workers = NUM_WORKERS,\r\n",
    "                                shuffle=True)\r\n",
    "\r\n",
    "testSet_Loader = DataLoader(testSet,\r\n",
    "                            batch_size = 1,\r\n",
    "                            num_workers = NUM_WORKERS,\r\n",
    "                            shuffle=True)\r\n",
    "\r\n",
    "criterion = torch.nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=LEARNING_RATE)\r\n",
    "\r\n",
    "\r\n",
    "if __name__ == '__main__':\r\n",
    "\r\n",
    "    #   training phase\r\n",
    "    for epoch in range(EPOCH_NUM):\r\n",
    "        print(\"trainin on Epoch:[{}/{}]\".format(epoch+1,EPOCH_NUM))\r\n",
    "\r\n",
    "        for uselessnum,data in enumerate(trainingSet_Loader,0):\r\n",
    "            pic,label = data\r\n",
    "            pic = pic.to(device)\r\n",
    "            loss = 0    #   The sum of losses\r\n",
    "            output = net(pic).transpose(0,2).transpose(1,3).view(388 ** 2,BATCH_SIZE,9)\r\n",
    "            optimizer.zero_grad()\r\n",
    "\r\n",
    "            for index in range(388 ** 2):\r\n",
    "                target = torch.Tensor([int(i[index]) for i in label]).long().to(device)\r\n",
    "                loss += criterion(output[index],target)\r\n",
    "\r\n",
    "            print(\"Optimizing!!\")\r\n",
    "            loss.backward()\r\n",
    "            optimizer.step()\r\n",
    "            print(\"{} pic done!! totalloss:{}\".format(uselessnum+1,loss))\r\n",
    "\r\n",
    "        torch.save(net, \"C:/Users/29147/source/repos/U-Netunet_epoch\"+str(epoch)+\".pth\")\r\n",
    "    \r\n",
    "        #   testing phase\r\n",
    "        for uselessnum,data in enumerate(testSet_Loader,0):\r\n",
    "            pic,label = data\r\n",
    "            pic = pic.to(device)\r\n",
    "            output = net(pic.detach()).transpose(0,2).transpose(1,3).view(388 ** 2,1,9)\r\n",
    "\r\n",
    "            correct_count = 0.\r\n",
    "            for index in range(388 ** 2):\r\n",
    "                target = int(label[0][index])\r\n",
    "                if torch.argmax(output[index][0]) == target:\r\n",
    "                    correct_count += 1\r\n",
    "\r\n",
    "            percision = correct_count/388 ** 2\r\n",
    "            print(\"testset acc:{}\".format(percision))\r\n",
    "        "
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "663e9bff0f8e489cfb11a535201dd029d3f4b5dbba25ed4b671d30c0c2c6bfa9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}